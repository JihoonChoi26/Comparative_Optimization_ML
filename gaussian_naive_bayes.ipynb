{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43522481-6f3e-4b4d-8ed1-61531fdfed2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to: 777\n",
      "[0.15266373 0.30235661 0.06203641]\n",
      "[0.15266373 0.30235661 0.06203641]\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from datetime import date, datetime\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "import seaborn as sns\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# Jupyter Notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "def set_seeds(seed=777):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "SEED = 777\n",
    "set_seeds(SEED)\n",
    "print(f'Random seed set to: {SEED}')\n",
    "# Checking\n",
    "print(np.random.rand(3))\n",
    "set_seeds(SEED)\n",
    "print(np.random.rand(3))\n",
    "\n",
    "# Display entire DataFrame\n",
    "def print_all(df):\n",
    "    with pd.option_context('display.max_rows', None, \n",
    "                           'display.max_columns', None, \n",
    "                           'display.float_format', '{:,.4f}'.format):\n",
    "        display(df)\n",
    "# Display entire columns\n",
    "def print_cols(df, n=5): \n",
    "    with pd.option_context('display.max_columns', None,\n",
    "                          'display.float_format', '{:,.4f}'.format):\n",
    "        print(df.shape)\n",
    "        display(df[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "560734bc-47a4-4cc1-92be-1c92240f5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ba88e0-e1d1-4be6-8119-f36f267b3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Configurations\n",
    "\n",
    "# Path\n",
    "# Get the path of the current script file\n",
    "CURRENT_DIR = os.getcwd()\n",
    "\n",
    "# Move up one level to the parent directory\n",
    "PARENT_DIR = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Path to data directory\n",
    "DATA_ROOT = os.path.join(CURRENT_DIR, 'data')\n",
    "\n",
    "# Path to dataset files\n",
    "TRAIN_DATA_PATH = os.path.join(DATA_ROOT, 'train_scaled.csv')\n",
    "TEST_DATA_PATH = os.path.join(DATA_ROOT, 'test_scaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a60c7c4-b417-454e-a4bb-3bba7f0b1f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target column\n",
    "target_col = 'def_pay'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efad3c5-d61f-4e77-a721-f816b6d8c51e",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdcc3919-9841-4270-8871-729da4ba2e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>limit_bal</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>age</th>\n",
       "      <th>pay_1</th>\n",
       "      <th>pay_2</th>\n",
       "      <th>pay_3</th>\n",
       "      <th>pay_4</th>\n",
       "      <th>pay_5</th>\n",
       "      <th>pay_6</th>\n",
       "      <th>bill_amt1</th>\n",
       "      <th>bill_amt2</th>\n",
       "      <th>bill_amt3</th>\n",
       "      <th>bill_amt4</th>\n",
       "      <th>bill_amt5</th>\n",
       "      <th>bill_amt6</th>\n",
       "      <th>pay_amt1</th>\n",
       "      <th>pay_amt2</th>\n",
       "      <th>pay_amt3</th>\n",
       "      <th>pay_amt4</th>\n",
       "      <th>pay_amt5</th>\n",
       "      <th>pay_amt6</th>\n",
       "      <th>edu_1</th>\n",
       "      <th>edu_2</th>\n",
       "      <th>edu_3</th>\n",
       "      <th>marr_1</th>\n",
       "      <th>marr_2</th>\n",
       "      <th>def_pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.6761</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.1345</td>\n",
       "      <td>-0.4695</td>\n",
       "      <td>-0.4000</td>\n",
       "      <td>-0.3889</td>\n",
       "      <td>-0.3446</td>\n",
       "      <td>-0.3127</td>\n",
       "      <td>-0.3195</td>\n",
       "      <td>-0.0815</td>\n",
       "      <td>-0.0624</td>\n",
       "      <td>-0.0387</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>-0.2138</td>\n",
       "      <td>-0.1676</td>\n",
       "      <td>-0.1818</td>\n",
       "      <td>-0.2166</td>\n",
       "      <td>-0.0966</td>\n",
       "      <td>-0.2932</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9401</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4672</td>\n",
       "      <td>-0.4695</td>\n",
       "      <td>-0.4000</td>\n",
       "      <td>-0.3889</td>\n",
       "      <td>-0.3446</td>\n",
       "      <td>-0.3127</td>\n",
       "      <td>-0.3195</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0663</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1729</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.2854</td>\n",
       "      <td>-0.1873</td>\n",
       "      <td>-0.1752</td>\n",
       "      <td>-0.1831</td>\n",
       "      <td>-0.1844</td>\n",
       "      <td>-0.1866</td>\n",
       "      <td>-0.1795</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   limit_bal  sex_female     age   pay_1   pay_2   pay_3   pay_4   pay_5  \\\n",
       "0    -0.6761           1 -1.1345 -0.4695 -0.4000 -0.3889 -0.3446 -0.3127   \n",
       "1     0.9401           1  1.4672 -0.4695 -0.4000 -0.3889 -0.3446 -0.3127   \n",
       "\n",
       "    pay_6  bill_amt1  bill_amt2  bill_amt3  bill_amt4  bill_amt5  bill_amt6  \\\n",
       "0 -0.3195    -0.0815    -0.0624    -0.0387     0.0062     0.0393     0.0865   \n",
       "1 -0.3195     0.0198     0.0663     0.0990     0.1729     0.2424     0.2854   \n",
       "\n",
       "   pay_amt1  pay_amt2  pay_amt3  pay_amt4  pay_amt5  pay_amt6  edu_1  edu_2  \\\n",
       "0   -0.2138   -0.1676   -0.1818   -0.2166   -0.0966   -0.2932      0      1   \n",
       "1   -0.1873   -0.1752   -0.1831   -0.1844   -0.1866   -0.1795      0      1   \n",
       "\n",
       "   edu_3  marr_1  marr_2 def_pay  \n",
       "0      0       0       1       0  \n",
       "1      0       0       0       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>limit_bal</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>age</th>\n",
       "      <th>pay_1</th>\n",
       "      <th>pay_2</th>\n",
       "      <th>pay_3</th>\n",
       "      <th>pay_4</th>\n",
       "      <th>pay_5</th>\n",
       "      <th>pay_6</th>\n",
       "      <th>bill_amt1</th>\n",
       "      <th>bill_amt2</th>\n",
       "      <th>bill_amt3</th>\n",
       "      <th>bill_amt4</th>\n",
       "      <th>bill_amt5</th>\n",
       "      <th>bill_amt6</th>\n",
       "      <th>pay_amt1</th>\n",
       "      <th>pay_amt2</th>\n",
       "      <th>pay_amt3</th>\n",
       "      <th>pay_amt4</th>\n",
       "      <th>pay_amt5</th>\n",
       "      <th>pay_amt6</th>\n",
       "      <th>edu_1</th>\n",
       "      <th>edu_2</th>\n",
       "      <th>edu_3</th>\n",
       "      <th>marr_1</th>\n",
       "      <th>marr_2</th>\n",
       "      <th>def_pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.1374</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.9177</td>\n",
       "      <td>-0.4695</td>\n",
       "      <td>-0.4000</td>\n",
       "      <td>-0.3889</td>\n",
       "      <td>-0.3446</td>\n",
       "      <td>-0.3127</td>\n",
       "      <td>-0.3195</td>\n",
       "      <td>-0.6753</td>\n",
       "      <td>-0.6666</td>\n",
       "      <td>-0.5963</td>\n",
       "      <td>-0.6015</td>\n",
       "      <td>0.4911</td>\n",
       "      <td>0.4874</td>\n",
       "      <td>-0.2319</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>-0.0353</td>\n",
       "      <td>4.3094</td>\n",
       "      <td>-0.1187</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2474</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3757</td>\n",
       "      <td>2.1586</td>\n",
       "      <td>-0.4000</td>\n",
       "      <td>-0.3889</td>\n",
       "      <td>-0.3446</td>\n",
       "      <td>-0.3127</td>\n",
       "      <td>-0.3195</td>\n",
       "      <td>1.4848</td>\n",
       "      <td>1.6005</td>\n",
       "      <td>0.5041</td>\n",
       "      <td>-0.6737</td>\n",
       "      <td>-0.6642</td>\n",
       "      <td>-0.6534</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>-0.0854</td>\n",
       "      <td>-0.2882</td>\n",
       "      <td>-0.3152</td>\n",
       "      <td>-0.3228</td>\n",
       "      <td>-0.2932</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   limit_bal  sex_female     age   pay_1   pay_2   pay_3   pay_4   pay_5  \\\n",
       "0    -0.1374           1 -0.9177 -0.4695 -0.4000 -0.3889 -0.3446 -0.3127   \n",
       "1     0.2474           0 -0.3757  2.1586 -0.4000 -0.3889 -0.3446 -0.3127   \n",
       "\n",
       "    pay_6  bill_amt1  bill_amt2  bill_amt3  bill_amt4  bill_amt5  bill_amt6  \\\n",
       "0 -0.3195    -0.6753    -0.6666    -0.5963    -0.6015     0.4911     0.4874   \n",
       "1 -0.3195     1.4848     1.6005     0.5041    -0.6737    -0.6642    -0.6534   \n",
       "\n",
       "   pay_amt1  pay_amt2  pay_amt3  pay_amt4  pay_amt5  pay_amt6  edu_1  edu_2  \\\n",
       "0   -0.2319   -0.0118   -0.0353    4.3094   -0.1187   -0.1250      0      1   \n",
       "1    0.1158   -0.0854   -0.2882   -0.3152   -0.3228   -0.2932      0      1   \n",
       "\n",
       "   edu_3  marr_1  marr_2 def_pay  \n",
       "0      0       0       1       0  \n",
       "1      0       0       1       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "train_df = pd.read_csv(TRAIN_DATA_PATH)\n",
    "test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "\n",
    "train_df[target_col] = train_df[target_col].astype('category')\n",
    "test_df[target_col] = test_df[target_col].astype('category')\n",
    "\n",
    "print_cols(train_df, 2)\n",
    "print_cols(test_df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc98aba3-1fdb-48f7-9f91-420f2da34f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24000 entries, 0 to 23999\n",
      "Data columns (total 27 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   limit_bal   24000 non-null  float64 \n",
      " 1   sex_female  24000 non-null  int64   \n",
      " 2   age         24000 non-null  float64 \n",
      " 3   pay_1       24000 non-null  float64 \n",
      " 4   pay_2       24000 non-null  float64 \n",
      " 5   pay_3       24000 non-null  float64 \n",
      " 6   pay_4       24000 non-null  float64 \n",
      " 7   pay_5       24000 non-null  float64 \n",
      " 8   pay_6       24000 non-null  float64 \n",
      " 9   bill_amt1   24000 non-null  float64 \n",
      " 10  bill_amt2   24000 non-null  float64 \n",
      " 11  bill_amt3   24000 non-null  float64 \n",
      " 12  bill_amt4   24000 non-null  float64 \n",
      " 13  bill_amt5   24000 non-null  float64 \n",
      " 14  bill_amt6   24000 non-null  float64 \n",
      " 15  pay_amt1    24000 non-null  float64 \n",
      " 16  pay_amt2    24000 non-null  float64 \n",
      " 17  pay_amt3    24000 non-null  float64 \n",
      " 18  pay_amt4    24000 non-null  float64 \n",
      " 19  pay_amt5    24000 non-null  float64 \n",
      " 20  pay_amt6    24000 non-null  float64 \n",
      " 21  edu_1       24000 non-null  int64   \n",
      " 22  edu_2       24000 non-null  int64   \n",
      " 23  edu_3       24000 non-null  int64   \n",
      " 24  marr_1      24000 non-null  int64   \n",
      " 25  marr_2      24000 non-null  int64   \n",
      " 26  def_pay     24000 non-null  category\n",
      "dtypes: category(1), float64(20), int64(6)\n",
      "memory usage: 4.8 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a55a1b0-ac5f-487e-a551-932f9ee1191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split target(y), features(X), train, test datasets\n",
    "\n",
    "X_train = train_df.drop(target_col, axis=1)\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "X_test = test_df.drop(target_col, axis=1)\n",
    "y_test = test_df[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b78bb3-e52b-4d8d-bfd8-63b77c95bccd",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes (GNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a28e02ee-4bdd-4104-8f54-f6890b028458",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGaussianNB:\n",
    "    '''\n",
    "    Simplified Gaussian Naive Bayes Classifier\n",
    "        \n",
    "    Core Ideas:\n",
    "    - Bayes' Theorem: P(y|x) ∝ P(y) * P(x|y)\n",
    "    - Naive Assumption: Features are independent of each other\n",
    "    - Gaussian Assumption: Each feature follows a normal distribution\n",
    "        \n",
    "    Therefore: P(x|y) = ∏ P(x_i|y) where P(x_i|y) ~ N(μ_yi, σ²_yi)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Initialization: Parameters to be stored after training\n",
    "        '''\n",
    "        self.classes = None # Class labels (e.g., [0, 1])\n",
    "        self.class_priors = None # P(y): Prior probability of each class\n",
    "        self.means = None # μ: Mean for each (class, feature) pair\n",
    "        self.variances = None # σ²: Variance for each (class, feature) pair\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Train the model: Calculate mean, variance, and prior probability for each class\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Feature matrix of training data\n",
    "        y : array-like, shape (n_samples,)\n",
    "            Target labels of training data\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        self : Trained model object\n",
    "        \n",
    "        Training Process:\n",
    "        1. Separate data by each class\n",
    "        2. Calculate prior for each class: P(y=c) = (# of samples in class c) / (total # of samples)\n",
    "        3. Calculate mean (μ) and variance (σ²) for each (class, feature) pair\n",
    "        '''\n",
    "        # Convert DataFrame to numpy array (for consistency in internal calculations)\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        \n",
    "        # Extract unique class labels (e.g., [0, 1])\n",
    "        self.classes = np.unique(y)\n",
    "        n_classes = len(self.classes) # Number of classes (2 for binary)\n",
    "        n_features = X.shape[1] # Number of features\n",
    "        \n",
    "        # Initialize arrays to store training results\n",
    "        # class_priors: shape (n_classes,) - one probability per class\n",
    "        # means: shape (n_classes, n_features) - mean for each class and feature\n",
    "        # variances: shape (n_classes, n_features) - variance for each class and feature\n",
    "        self.class_priors = np.zeros(n_classes)\n",
    "        self.means = np.zeros((n_classes, n_features))\n",
    "        self.variances = np.zeros((n_classes, n_features))\n",
    "        \n",
    "        # Calculate statistics for each class\n",
    "        for i, c in enumerate(self.classes):\n",
    "            # Extract only samples belonging to current class c\n",
    "            # X_c: shape (n_samples_in_class_c, n_features)\n",
    "            X_c = X[y == c]\n",
    "            \n",
    "            # 1. Calculate prior probability: P(y=c)\n",
    "            # Proportion of class c among all samples\n",
    "            self.class_priors[i] = len(X_c) / len(X)\n",
    "            \n",
    "            # 2. Calculate mean for each feature: μ_c\n",
    "            # X_c.mean(axis=0): Calculate mean for each column (feature)\n",
    "            # Result: shape (n_features,) - one mean value per feature\n",
    "            self.means[i] = X_c.mean(axis=0)\n",
    "            \n",
    "            # 3. Calculate variance for each feature: σ²_c\n",
    "            # X_c.var(axis=0): Calculate variance for each column (feature)\n",
    "            # Result: shape (n_features,) - one variance value per feature\n",
    "            self.variances[i] = X_c.var(axis=0) + 1e-9 # + 1e-9: Prevent variance from becoming 0 (avoid division by zero later)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def _gaussian_log_likelihood(self, x, mean, var):\n",
    "        '''\n",
    "        Calculate log-likelihood of Gaussian distribution for a single sample\n",
    "\n",
    "        Logarithm\n",
    "        - Multiplying very small probability values --> risk of underflow\n",
    "        - In log space, multiplication becomes addition, which is numerically stable\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : array-like, shape (n_features,)\n",
    "            Feature vector of a single sample\n",
    "        mean : array-like, shape (n_features,)\n",
    "            Mean of each feature for a specific class\n",
    "        var : array-like, shape (n_features,)\n",
    "            Variance of each feature for a specific class\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        log_likelihood : float\n",
    "            log P(x|y) = sum over all log P(x_i|y)\n",
    "        '''\n",
    "        # Term 1: -0.5 * Σ log(2πσ²)\n",
    "        # Calculate for each feature and sum all\n",
    "        term1 = -0.5 * np.sum(np.log(2 * np.pi * var))\n",
    "        \n",
    "        # Term 2: -0.5 * Σ (x_i - μ)² / σ²\n",
    "        # For each feature, divide (observed - mean)² by variance, then sum all\n",
    "        term2 = -0.5 * np.sum((x - mean)**2 / var)\n",
    "        \n",
    "        return term1 + term2\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predict classes for test data\n",
    "\n",
    "        For each sample x:\n",
    "        1. Calculate posterior probability for each class c\n",
    "        2. Select the class with highest posterior probability\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Samples to predict\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        predictions : array, shape (n_samples,)\n",
    "            Predicted class for each sample\n",
    "        '''\n",
    "        # Convert DataFrame to numpy array\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        # Iterate through each sample (row) for prediction\n",
    "        for x in X: # x: shape (n_features,) - single sample\n",
    "            # Calculate posterior probability for each class\n",
    "            posteriors = [] # Store log P(y|x) for each class\n",
    "            \n",
    "            # Calculate posterior probability for each class\n",
    "            for i, c in enumerate(self.classes):\n",
    "                # 1. Prior probability: log P(y=c)\n",
    "                # self.class_priors[i] is a value between 0~1, so take log\n",
    "                prior = np.log(self.class_priors[i])\n",
    "                \n",
    "                # 2. Likelihood: log P(x|y=c)\n",
    "                # Probability that current sample x comes from distribution of class c\n",
    "                # self.means[i]: Mean of each feature for class c (shape: n_features,)\n",
    "                # self.variances[i]: Variance of each feature for class c (shape: n_features,)\n",
    "                likelihood = self._gaussian_log_likelihood(\n",
    "                    x, self.means[i], self.variances[i]\n",
    "                )\n",
    "                \n",
    "                # 3. Posterior probability: log P(y=c|x) ∝ log P(y=c) + log P(x|y=c)\n",
    "                # Log version of Bayes' Theorem\n",
    "                # (Denominator P(x) is common to all classes, so can be omitted for comparison)\n",
    "                posteriors.append(prior + likelihood) # e.g., list [np.float64(-77.65), np.float64(-53.45)]\n",
    "            \n",
    "            # 4. Select the class with highest posterior probability\n",
    "            # np.argmax(posteriors): Returns index of maximum value\n",
    "            # self.classes[index]: Actual class label at that index\n",
    "            predictions.append(self.classes[np.argmax(posteriors)]) # -77.65 < -53.45 => index 1\n",
    "        \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        '''\n",
    "        Return probability for each class\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Samples to predict\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        probabilities : array, shape (n_samples, n_classes)\n",
    "            Probability of each class for each sample\n",
    "            e.g., [[0.8, 0.2], [0.3, 0.7], ...] (for binary classification)\n",
    "            \n",
    "        Probability Calculation Process:\n",
    "        ---------------------------------\n",
    "        1. Calculate log posterior probability for each class (same as predict)\n",
    "        2. Convert to actual probabilities using Softmax transformation\n",
    "           P(y=c|x) = exp(log P(y=c|x)) / Σ exp(log P(y=k|x))\n",
    "        3. Use log-sum-exp trick for numerical stability\n",
    "        '''\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        \n",
    "        probs = []\n",
    "        \n",
    "        # Iterate through each sample (row)\n",
    "        for x in X: # x: shape (n_features,) - single sample\n",
    "            posteriors = []\n",
    "            \n",
    "            # Calculate log posterior probability for each class (same as predict method)\n",
    "            for i in range(len(self.classes)):\n",
    "                prior = np.log(self.class_priors[i])\n",
    "                likelihood = self._gaussian_log_likelihood(\n",
    "                    x, self.means[i], self.variances[i]\n",
    "                )\n",
    "                posteriors.append(prior + likelihood)\n",
    "                \n",
    "            # Convert posteriors to numpy array\n",
    "            # shape: (n_classes,) - log P(y|x) for each class\n",
    "            posteriors = np.array(posteriors) # list -> ndarray object\n",
    "            \n",
    "            # Softmax transformation with log-sum-exp trick\n",
    "            # -----------------------------------------------\n",
    "            # Goal: P(y=c|x) = exp(log P(y=c|x)) / Σ exp(log P(y=k|x))\n",
    "            # \n",
    "            # Problem: exp() can create very large/small values causing overflow/underflow\n",
    "            # \n",
    "            # Solution: Log-sum-exp trick\n",
    "            # 1. Subtract maximum value for stabilization: posteriors - max(posteriors)\n",
    "            # This makes the largest value 0, and the rest negative\n",
    "            # Mathematically equivalent: exp(a-M) / Σexp(b-M) = exp(a) / Σexp(b)\n",
    "            posteriors = posteriors - np.max(posteriors)\n",
    "            \n",
    "            # 2. Apply exponential function\n",
    "            # Now all values are ≤ 0, so no overflow\n",
    "            exp_posteriors = np.exp(posteriors)\n",
    "            \n",
    "            # 3. Normalize: Divide each value by total sum to convert to probability\n",
    "            # Sum of results = 1.0 (axiom of probability)\n",
    "            probs.append(exp_posteriors / np.sum(exp_posteriors))\n",
    "            \n",
    "        # shape: (n_samples, n_classes)\n",
    "        # Each row is one sample, each column is one class\n",
    "        return np.array(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c031961-ba80-4592-95e6-a8cea339c3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB (from scratch)\n",
      "Accuracy: 0.7713\n",
      "F1 Score: 0.5206\n",
      "ROC-AUC:  0.7471\n",
      "PR-AUC:   0.4918\n",
      "Log Loss: 1.6005\n",
      "\n",
      "GaussianNB (sklearn)\n",
      "Accuracy: 0.7713\n",
      "F1 Score: 0.5206\n",
      "ROC-AUC:  0.7471\n",
      "PR-AUC:   0.4915\n",
      "Log Loss: 1.6016\n"
     ]
    }
   ],
   "source": [
    "# Make sure target is integer (0/1)\n",
    "y_train_int = y_train.astype(int)\n",
    "y_test_int = y_test.astype(int)\n",
    "\n",
    "# GaussianNB built from scratch\n",
    "model = SimpleGaussianNB()\n",
    "model.fit(X_train, y_train) # train on integers\n",
    "\n",
    "# Predict class labels (0 or 1)\n",
    "my_preds = model.predict(X_test)\n",
    "\n",
    "# Predict probability of default (class 1)\n",
    "my_proba = model.predict_proba(X_test)\n",
    "my_proba = my_proba[:, 1] # second column = positive class probability P(default)\n",
    "\n",
    "print(\"GaussianNB (from scratch)\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_int, my_preds):.4f}\") # % of correct predictions (0 or 1)\n",
    "print(f\"F1 Score: {f1_score(y_test_int, my_preds):.4f}\") # balance of precision & recall\n",
    "print(f\"ROC-AUC:  {roc_auc_score(y_test_int, my_proba):.4f}\") # how well model ranks defaulters higher\n",
    "print(f\"PR-AUC:   {average_precision_score(y_test_int, my_proba):.4f}\") # precision-focused AUC; strong on imbalanced data\n",
    "print(f\"Log Loss: {log_loss(y_test_int, my_proba):.4f}\") # measures how confident and correct predictions are; penalty for wrong confidence\n",
    "\n",
    "# sklearn GaussianNB (benchmark)\n",
    "sklearn_gnb = GaussianNB()\n",
    "sklearn_gnb.fit(X_train, y_train_int)\n",
    "\n",
    "# Predict class labels and probability\n",
    "sklearn_preds = sklearn_gnb.predict(X_test)\n",
    "sklearn_proba = sklearn_gnb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nGaussianNB (sklearn)\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_int, sklearn_preds):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test_int, sklearn_preds):.4f}\")\n",
    "print(f\"ROC-AUC:  {roc_auc_score(y_test_int, sklearn_proba):.4f}\")\n",
    "print(f\"PR-AUC:   {average_precision_score(y_test_int, sklearn_proba):.4f}\")\n",
    "print(f\"Log Loss: {log_loss(y_test_int, sklearn_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1780834-65cd-42e9-983d-a4ad1657f8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
